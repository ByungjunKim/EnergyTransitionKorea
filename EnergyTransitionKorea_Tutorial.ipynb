{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMWqbjcfaUjW1c3QgjjUj5E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ByungjunKim/EnergyTransitionKorea/blob/main/EnergyTransitionKorea_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding the public’s attitudes towards energy and environmental issues using text data\n",
        "\n",
        "실습용 코드 (CatBoost 모델링 제외한 각종 데이터 전처리와 분류 모델 써보기)  "
      ],
      "metadata": {
        "id": "Vs-RAcbPYt0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 패키지 설치\n",
        "!pip install -q transformers lightning torch gdown kiwipiepy"
      ],
      "metadata": {
        "id": "4mIYnbBFY3qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 파이썬 패키지 로드\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch ## version >= 1.8.2\n",
        "import torch.nn as nn\n",
        "\n",
        "import pytorch_lightning as pl ## version == 1.9.0\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel ## version == 4.12.3\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "import pandas as pd\n",
        "import polars as pls\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from json import JSONDecodeError\n",
        "import pickle\n",
        "\n",
        "tqdm.pandas()\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.dpi\"] = 200 # DPI 고화질로 향상\n",
        "# plt.rcParams['font.family'] = 'NanumGothic'\n",
        "import seaborn as sns\n",
        "\n",
        "# from mpire import WorkerPool\n",
        "# import multiprocessing\n",
        "# n_cpu = multiprocessing.cpu_count()\n",
        "from itertools import chain\n",
        "import glob\n",
        "from natsort import natsorted\n",
        "from scipy import stats\n",
        "import gdown\n",
        "\n",
        "from kiwipiepy import Kiwi\n",
        "kiwi = Kiwi(model_type='sbg')\n",
        "\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim import corpora, models\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "from transformers import AutoTokenizer, BertForSequenceClassification, logging\n",
        "from transformers import TextClassificationPipeline, BertForSequenceClassification, AutoTokenizer\n",
        "logging.set_verbosity_error()\n",
        "import re\n",
        "# import torch\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import kruskal"
      ],
      "metadata": {
        "id": "NBBykdPrXaZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNVM-5L1Wtv-"
      },
      "outputs": [],
      "source": [
        "# Clone\n",
        "!git clone https://github.com/ByungjunKim/EnergyTransitionKorea.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Load"
      ],
      "metadata": {
        "id": "gbi3Ed13ZOsO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### news"
      ],
      "metadata": {
        "id": "8tCY4jivaP6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news = pd.read_excel('./EnergyTransitionKorea/data/news_df.xlsx')\n",
        "news"
      ],
      "metadata": {
        "id": "aaajPRD2ZQ4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 연구에 활용할 뉴스 기사만 선별하기 (inclusion 컬럼 활용)\n",
        "news = news.loc[news['inclusion']==1].reset_index(drop=True)\n",
        "news"
      ],
      "metadata": {
        "id": "GoVhrpZ-a2Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 제목의 긍정(1), 중립(0), 부정(-1) 분류 (복수의 연구자들의 qualitative한 분류)\n",
        "news['title_p/n'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "nVocnBCrbICd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 에너지 정책에 대한 논조 긍정(1), 중립(0), 부정(-1) 분류 (복수의 연구자들의 qualitative한 분류)\n",
        "news['e_policy_p/n'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "0jFAtYPRbxdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Profile\n",
        "# Reading the CSV file into a DataFrame\n",
        "user_profile_df = pd.read_csv('./EnergyTransitionKorea/data/user_profile_df.csv')\n",
        "user_profile_df"
      ],
      "metadata": {
        "id": "Z843B86mA0sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 댓글 데이터\n",
        "reply = pd.read_csv('./EnergyTransitionKorea/data/reply_df_catboost.csv')\n",
        "reply"
      ],
      "metadata": {
        "id": "sQG86JYSXHNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컬럼 확인\n",
        "reply.columns"
      ],
      "metadata": {
        "id": "SXTMITSCXk5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess\n",
        "파생변수(Derived Variable) 만들기"
      ],
      "metadata": {
        "id": "aKc_h0i1fwv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Tokenization for TTR"
      ],
      "metadata": {
        "id": "Axj4KTMNfyY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sent):\n",
        "    res = kiwi.tokenize(sent, normalize_coda=True)\n",
        "    return [word+'/'+tag for word, tag, _, _ in res\n",
        "            if not tag.startswith('W')] # 웹관련(w) 형태소 제거"
      ],
      "metadata": {
        "id": "ZzBXv6sthHku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이징(한국어 형태소 분석) 테스트\n",
        "kiwi.tokenize('안녕하세요 KAIST 넙죽이입니다. sdfkljskf@kaist.ac.kr')"
      ],
      "metadata": {
        "id": "8iZtBg2KZZgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이징(한국어 형태소 분석) 테스트\n",
        "tokens = tokenize('안녕하세요 KAIST 넙죽이입니다. 넙죽넙죽 sdfkljskf@kaist.ac.kr')\n",
        "tokens"
      ],
      "metadata": {
        "id": "iMws0xMyZPDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TTR(Type Token Ratio) 계산\n",
        "def calculate_ttr(tokens):\n",
        "    # Tokenize the text into words\n",
        "    # tokens = text.split()\n",
        "\n",
        "    # Count the total number of tokens\n",
        "    total_tokens = len(tokens)\n",
        "\n",
        "    if total_tokens!=0:\n",
        "        # Count the number of unique tokens (types)\n",
        "        unique_tokens = len(set(tokens))\n",
        "\n",
        "        # Calculate the Term-to-Term Ratio (TTR)\n",
        "        ttr = unique_tokens / total_tokens\n",
        "    else:\n",
        "        ttr = 0\n",
        "\n",
        "    return ttr"
      ],
      "metadata": {
        "id": "qIp2iZ53ZupK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_ttr(tokens)"
      ],
      "metadata": {
        "id": "vxDb4BumZyR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5분 내외 걸림\n",
        "reply['tokens'] = reply['reply'].progress_map(lambda x:tokenize(x))\n",
        "\n",
        "# with WorkerPool(n_jobs=n_cpu) as pool:\n",
        "#     tokens_list = pool.map(tokenize, reply['reply'].tolist(), progress_bar=True)"
      ],
      "metadata": {
        "id": "KblsYskpolXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply['tokens']"
      ],
      "metadata": {
        "id": "pXjFlLlTpygN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 상위 명사 추출하기"
      ],
      "metadata": {
        "id": "QJRQRavbrZ6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 명사만 추출 (NNG=보통명사, NNP=공유명사)\n",
        "nouns = reply['tokens'].tolist()\n",
        "nouns = [[w for w in l if w.split('/')[1]=='NNG' or w.split('/')[1]=='NNP'] for l in nouns]"
      ],
      "metadata": {
        "id": "VwNLVoW4rdGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 상위 n개 Unigram 확인\n",
        "nouns_tokens = chain(*nouns)\n",
        "cnt = Counter(nouns_tokens)\n",
        "pd.DataFrame(cnt.most_common(20), columns=['Unigram','Frequency'])"
      ],
      "metadata": {
        "id": "H16aAoN8sILE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_bigram(data_words,bigram_min_count):\n",
        "    bigram = gensim.models.Phrases(data_words, min_count=bigram_min_count)\n",
        "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "    # bigram으로 만들기\n",
        "    data_words_bigrams = [bigram_mod[doc] for doc in data_words] # 불용어 1차 제거 후에 bigram\n",
        "    return data_words_bigrams"
      ],
      "metadata": {
        "id": "4Dj7CQzDsJ1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigram = make_bigram(nouns,100)  # N회 이상 등장한 단어만 bigram 처리"
      ],
      "metadata": {
        "id": "1m0ew8E-sjdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bigram 단어 확인\n",
        "bigram_list = [word for sent in bigram for word in sent if \"_\" in word]\n",
        "pd.DataFrame(Counter(bigram_list).most_common(20), columns=['Bigram','Frequency']).to_excel('./bigram_keywords.xlsx')\n",
        "Counter(bigram_list).most_common(20) # 상위 N개"
      ],
      "metadata": {
        "id": "vXaRfXoXsm1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### User Clustering (K-means)"
      ],
      "metadata": {
        "id": "oJ_eFdsuf7jX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'start_date' column to datetime format\n",
        "user_profile_df['start_date'] = pd.to_datetime(user_profile_df['start_date'])\n",
        "\n",
        "# Calculate the number of days since the start date\n",
        "current_date = datetime.now()\n",
        "user_profile_df['days_since_start'] = (current_date - user_profile_df['start_date']).dt.days\n",
        "\n",
        "# Display the first few rows of the DataFrame with the new column\n",
        "user_profile_df.head()"
      ],
      "metadata": {
        "id": "3QrPgDU-hIJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove commas from the columns and convert them to integers\n",
        "columns_to_convert = ['sum_reply', 'sum_son_reply', 'recent_n_reply']\n",
        "\n",
        "for col in columns_to_convert:\n",
        "    user_profile_df[col] = user_profile_df[col].str.replace(',', '').astype(int)\n",
        "\n",
        "# Check the data types and first few rows to ensure the columns are converted correctly\n",
        "user_profile_df.dtypes, user_profile_df.head()"
      ],
      "metadata": {
        "id": "9yW3CJxABwvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the features for clustering\n",
        "selected_features = ['sum_reply', 'sum_son_reply', 'recent_n_reply', 'days_since_start']\n",
        "cluster_data = user_profile_df[selected_features]\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(cluster_data)\n",
        "\n",
        "# Apply K-means clustering (k=2 for \"heavy\" and \"normal\")\n",
        "kmeans = KMeans(n_clusters=2, random_state=0)\n",
        "kmeans.fit(scaled_data)\n",
        "\n",
        "# Add the cluster labels to the original DataFrame\n",
        "user_profile_df['user_type'] = np.where(kmeans.labels_ == 0, 'normal', 'heavy')\n",
        "\n",
        "# Display first few rows with the new 'user_type' column\n",
        "user_profile_df.head()"
      ],
      "metadata": {
        "id": "sIjBC_9VCNMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification Model"
      ],
      "metadata": {
        "id": "ajl14JsjgElH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### News Article Classification (한국언론진행재단에서 개발한 BERT 기반 분류 모델)\n",
        "https://github.com/KPF-bigkinds/BIGKINDS-LAB/tree/main/KPF-BERT-CLS"
      ],
      "metadata": {
        "id": "5sP12SK2gHSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KPFBERT(한국언론진흥재단 BERT 가져오기)\n",
        "!git clone https://github.com/KPFBERT/kpfbert.git"
      ],
      "metadata": {
        "id": "p1P9jyWy9zbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "big_label = ['정치', '경제', '사회', '문화', '국제', '스포츠', 'IT_과학']\n",
        "big_label2id = {label: i for i, label in enumerate(big_label)}\n",
        "big_id2label = {i: label for label, i in big_label2id.items()}"
      ],
      "metadata": {
        "id": "Zs8lX7u8hIms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "big_id2label"
      ],
      "metadata": {
        "id": "_nCI8W5z-W3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer 및 model 불러오기\n",
        "kpf_tokenizer = AutoTokenizer.from_pretrained(\"kpfbert\")\n",
        "# huggingface 분류모델 불러오기\n",
        "kpf_model1 = BertForSequenceClassification.from_pretrained(\"KPF/KPF-bert-cls2\")"
      ],
      "metadata": {
        "id": "qD1VB7p99DGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = TextClassificationPipeline(\n",
        "        model = kpf_model1,\n",
        "        tokenizer = kpf_tokenizer,\n",
        "        device = 0, # gpu: 0\n",
        "        top_k=None,\n",
        "        function_to_apply = 'sigmoid')"
      ],
      "metadata": {
        "id": "B455olAl9GHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 신문 기사 제목 분류 연습\n",
        "sorted(pipe('''여소야대 높은 벽에 ‘부동산稅’ 빠진 세법 개정안… 세수효과 -4719억원''')[0], key=lambda d: d['label'])"
      ],
      "metadata": {
        "id": "NJRxTmPs-IcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Emotion Classification\n",
        "https://github.com/kjhkjh95/Moral_Emotion_Dataset  \n",
        "김재홍, 정채윤, 차미영, 이원재. (2023). KOME(Korean Online Moral Emotion): 세부 분류를 위한 한국어 도덕감정 데이터셋. 한국정보과학회 학술발표논문집.\n",
        "https://www.dbpia.co.kr/pdf/pdfView.do?nodeId=NODE11488020"
      ],
      "metadata": {
        "id": "_67PJrxmgPbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "electra = AutoModel.from_pretrained(\"beomi/KcELECTRA-base-v2022\", return_dict=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base-v2022\")\n",
        "LABELS = ['Neutral', 'Non-Moral-Emotion', 'Other-Condemming', 'Other-Praising', 'Other-Suffering', 'Self-Conscious']"
      ],
      "metadata": {
        "id": "i226bxAMhJAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/1TWQek8ouPLrunIFvB-aOLbbS6MO2iozc/view?usp=sharing\n",
        "# KOME 체크포인트 파일 다운로드\n",
        "gdown.download(id='1TWQek8ouPLrunIFvB-aOLbbS6MO2iozc',output='best_model.ckpt')"
      ],
      "metadata": {
        "id": "agFQTx5im_JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "electra = AutoModel.from_pretrained(\"beomi/KcELECTRA-base-v2022\", return_dict=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base-v2022\")\n",
        "LABELS = ['Neutral', 'Non-Moral-Emotion', 'Other-Condemming', 'Other-Praising', 'Other-Suffering', 'Self-Conscious']\n",
        "\n",
        "\n",
        "INITIAL_LR = 2e-5\n",
        "class KOTETagger(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, n_training_steps=None, n_warmup_steps=None, gamma_for_expLR=None):\n",
        "        super().__init__()\n",
        "        self.electra = electra\n",
        "        self.classifier = nn.Linear(self.electra.config.hidden_size, 6) ## the label dimension == 6 <-- what an ominous number for asians though... <-- I didn't intend it!\n",
        "        self.n_training_steps = n_training_steps\n",
        "        self.n_warmup_steps = n_warmup_steps\n",
        "\n",
        "        ## the loss\n",
        "        self.criterion = nn.BCELoss()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        output = self.electra(input_ids, attention_mask=attention_mask)\n",
        "        output = output.last_hidden_state[:,0,:] ## [CLS] of the last hidden state\n",
        "        output = self.classifier(output)\n",
        "        output = torch.sigmoid(output)\n",
        "        loss = 0\n",
        "        if labels is not None:\n",
        "            loss = self.criterion(output, labels)\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        return loss, output\n",
        "\n",
        "    def step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        loss, outputs = self.forward(input_ids, attention_mask, labels)\n",
        "\n",
        "        preds = outputs\n",
        "\n",
        "        y_true = list(labels.detach().cpu())\n",
        "        y_pred = list(preds.detach().cpu())\n",
        "\n",
        "        return {\"loss\": loss, \"y_true\": y_true, \"y_pred\": y_pred}\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.step(batch, batch_idx)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self.step(batch, batch_idx)\n",
        "\n",
        "    def epoch_end(self, outputs, state=\"train\"):\n",
        "        loss = torch.tensor(0, dtype=torch.float)\n",
        "        for out in outputs:\n",
        "            loss += out[\"loss\"].detach().cpu()\n",
        "        loss = loss / len(outputs)\n",
        "\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        for out in outputs:\n",
        "            y_true += out[\"y_true\"]\n",
        "            y_pred += out[\"y_pred\"]\n",
        "\n",
        "        self.log(state + \"_loss\", float(loss), on_epoch=True, prog_bar=True)\n",
        "        print(f\"[Epoch {self.trainer.current_epoch} {state.upper()}] Loss: {loss}\")\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        self.epoch_end(outputs, state=\"train\")\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        self.epoch_end(outputs, state=\"val\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.parameters(), lr=INITIAL_LR, weight_decay=0.01)\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=self.n_warmup_steps,\n",
        "            num_training_steps=self.n_training_steps\n",
        "        )\n",
        "\n",
        "        return dict(\n",
        "          optimizer=optimizer,\n",
        "          lr_scheduler=dict(\n",
        "            scheduler=scheduler,\n",
        "            interval=\"step\"\n",
        "          )\n",
        "        )"
      ],
      "metadata": {
        "id": "suEvA7v6kmkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "\n",
        "best_ckpt = \"./best_model.ckpt\"\n",
        "\n",
        "moral_emotion_detection = KOTETagger.load_from_checkpoint(best_ckpt, map_location=torch.device('cuda'),strict=False)\n",
        "moral_emotion_detection.eval()\n",
        "moral_emotion_detection.freeze()\n",
        "DEVICE = torch.device(f\"cuda:0\")  # GPU 번호 설정\n",
        "moral_emotion_detection = moral_emotion_detection.to(DEVICE)"
      ],
      "metadata": {
        "id": "unBhCRGypLSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "THRESHOLD = 0.8  # 예를 들어 0.8로 지정. 원하는 값으로 조절 가능.\n",
        "\n",
        "sample_text = \"아이고 저 사람들은 불쌍해서 어떡하냐 ㅠㅠ\" # 분류하고 싶은 문장을 넣어보세요\n",
        "encoding = tokenizer.encode_plus(\n",
        "  sample_text,\n",
        "  add_special_tokens=True,\n",
        "  max_length=512,\n",
        "  return_token_type_ids=False,\n",
        "  padding=\"max_length\",\n",
        "  return_attention_mask=True,\n",
        "  return_tensors=\"pt\",\n",
        ")\n",
        "\n",
        "_, predictions = moral_emotion_detection(encoding[\"input_ids\"].to(DEVICE), encoding[\"attention_mask\"].to(DEVICE))\n",
        "predictions = predictions.flatten().cpu()\n",
        "for l, p in zip(LABELS, predictions):\n",
        "    if p < THRESHOLD:\n",
        "        continue\n",
        "    print(f\"{l}: {p}\")"
      ],
      "metadata": {
        "id": "JsDiOzyrrkC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA"
      ],
      "metadata": {
        "id": "eBV9SzXRhD9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### User Clustering"
      ],
      "metadata": {
        "id": "QWbhr7meCrpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_profile_df['user_type'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "Gsz-mp4rhGEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics for each user type\n",
        "selected_features = ['sum_reply', 'sum_son_reply', 'recent_n_reply', 'days_since_start']\n",
        "summary_stats = user_profile_df.groupby('user_type')[selected_features].describe()\n",
        "\n",
        "# Visualizations\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, feature in enumerate(selected_features, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    sns.boxplot(x='user_type', y=feature, data=user_profile_df)\n",
        "    plt.title(f'Boxplot of {feature} by User Type')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8LPHFe4bCt6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_stats['days_since_start']"
      ],
      "metadata": {
        "id": "Eynqo9wJC81z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizations\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, feature in enumerate(selected_features, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    # Q1, Q3, 그리고 IQR 계산\n",
        "    Q1 = user_profile_df[feature].quantile(0.25)\n",
        "    Q3 = user_profile_df[feature].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # IQR을 사용하여 이상치 찾기 및 제거\n",
        "    user_profile_df_ = user_profile_df[(user_profile_df[feature] >= Q1 - 1.5 * IQR) & (user_profile_df[feature] <= Q3 + 1.5 * IQR)]\n",
        "    sns.boxplot(x='user_type', y=feature, data=user_profile_df_)\n",
        "    plt.title(f'Boxplot of {feature} by User Type (IQR)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "otipdw2UDIgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### News Article Classification"
      ],
      "metadata": {
        "id": "7gP9TXPvDR5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reply.columns"
      ],
      "metadata": {
        "id": "6_086oeSDlWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "big_label = ['politics', 'economy', 'society', 'culture', 'international', 'sports', 'IT_science']\n",
        "reply[big_label].describe()"
      ],
      "metadata": {
        "id": "re0RbsSVDK4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.boxplot(data = reply[big_label])\n",
        "g.set_xticklabels(g.get_xticklabels(), rotation=45)"
      ],
      "metadata": {
        "id": "GOnYCn-uDvKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Emotion Classification"
      ],
      "metadata": {
        "id": "NHx5CdEtEAIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LABELS = ['Condemning','Praising', 'Suffering', 'Self-Conscious']\n",
        "reply[LABELS].describe()"
      ],
      "metadata": {
        "id": "PQvWmWd0DxDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.boxplot(data = reply[LABELS])\n",
        "g.set_xticklabels(g.get_xticklabels(), rotation=45)"
      ],
      "metadata": {
        "id": "lTTeyzQFEVzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Kruskal-Wallis H test (2개 이상의 집단의 평균 차이 검정)\n",
        "https://en.wikipedia.org/wiki/Kruskal%E2%80%93Wallis_one-way_analysis_of_variance"
      ],
      "metadata": {
        "id": "HDr8za61ENCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to perform the Kruskal-Wallis H test for the dependent variable based on the specified group column\n",
        "def perform_kruskal_test_single(df, group_column, dependent_var):\n",
        "    groups = [df[dependent_var][df[group_column] == group].values for group in df[group_column].unique() if group == group]  # Exclude NaN groups\n",
        "    h_stat, p_val = kruskal(*groups)\n",
        "    return h_stat, p_val\n",
        "\n",
        "# Perform the Kruskal-Wallis H test based on 'user_type', 'title_p/n', and 'e_policy_p/n' for 'Condemning' and store the results\n",
        "kruskal_results_single = {\n",
        "    'user_type': perform_kruskal_test_single(reply, 'user_type', 'Condemning'),\n",
        "    'title_p/n': perform_kruskal_test_single(reply, 'title_p/n', 'Condemning'),\n",
        "    'e_policy_p/n': perform_kruskal_test_single(reply, 'e_policy_p/n', 'Condemning')\n",
        "}\n",
        "\n",
        "kruskal_results_single"
      ],
      "metadata": {
        "id": "SZE_lAxEEpyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply.groupby('title_p/n')['Condemning'].describe()"
      ],
      "metadata": {
        "id": "mcYaUvvuFHCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply.boxplot(by='title_p/n', column='Condemning', grid=False)"
      ],
      "metadata": {
        "id": "6UV1sn19Fo40"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}